<!DOCTYPE html>
<html>
<title>Sentiment Analysis using Twitter Data</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://www.w3schools.com/lib/w3-theme-black.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css">
<style>
.responsive {
  width: 100%;
  height: auto;
}
.right-responsive {
  float: right;
  width: 50%%;
  padding: 5px;
  max-height:200px
}
.left-responsive {
  float: left;
  width: 50%%;
  padding: 5px;
  max-height:200px
}
</style>
<body>


<!-- Header -->
<header class="w3-container w3-theme w3-padding" id="myHeader">
  <i onclick="w3_open()" class="fa fa-bars w3-xlarge w3-button w3-theme"></i> 
  <div class="w3-center">
  <h1 class="w3-xxxlarge w3-animate-bottom">Sentiment Analysis using Twitter reviews</h1>
  </div>
</header>

<!-- Modal -->


<div class="w3-row-padding w3-center w3-margin-top">
<div class="w3-third">
  <div class="w3-card w3-container" style="min-height:460px">
  <h3>Objective</h3><br>
  <i class="fa fa-desktop w3-margin-bottom w3-text-theme" style="font-size:120px"></i>
  <p>This project aims to judge feedback/reviews of Google's self driving cars through twitter reviews by performing sentiment analysis using natural language
    processing in Python.
  </p>
  
  </div>
</div>

<div class="w3-third">
  <div class="w3-card w3-container" style="min-height:460px">
  <h3>Language & popular libraries Used</h3><br>
  <i class="fa fa-wrench w3-margin-bottom w3-text-theme" style="font-size:120px"></i>
  <b><p>Python</p></b>
  <p>NumPy</p>
  <p>Pandas</p>
  <p>NLTK (Natural Language ToolKit)</p>
  <p>Scikit-learn</p>
</div>
</div>

<div class="w3-third">
  <div class="w3-card w3-container" style="min-height:460px">
  <h3>High level process followed</h3><br>
  <i class="fa fa-diamond w3-margin-bottom w3-text-theme" style="font-size:120px"></i>
  <p>Data Cleaning and Exploratory Data Analysis</p>
  <p>Tokenization</p>
  <p>Classification</p>
  <p>Model Evaluation</p>
  </div>
</div>
</div>

<div class="w3-container">
<hr>

     
<div class="w3-center">
  <h2>Analysis & Recommendations</h2>
  <p>Please find below the process used to analyze the dataset. All graphs have been created using Matplotlib and Seaborn</p>
</div>   

<header class="w3-container w3-blue-grey">
<h2></h2>
</header>

<div class="w3-padding w3-white w3-display-container">
  <span onclick="this.parentElement.style.display='none'" class="w3-button w3-display-topright"></span>
  <h2>Data Cleaning and Exploratory Data Analysis</h2><hr>
  <p><b>Data Cleaning</b><br>This state consists of cleaning and preprocessing data in order to prepare it for modeling
    <ul style="list-style-type:circle;">
        <li>Start by reading the file using read_csv in pandas. Drop any unnecessary columns to focus on important data needed for analysis. 
            Currently columns Id, sentiment score, sentiment confidence and the tweet content were retained.</li>
        <li>Look for nulls within the dataset. Any nulls withing the sentiment confidence/score can be replaced using mean of the remaining data in the score/confidence 
                columns.</li>
        <li>Look for nulls within the dataset. Any nulls withing the sentiment confidence/score can be replaced using mean of the remaining data in the score/confidence 
            columns.</li> 
        <li>Some of the emoticons create weird symbols within the dataset and in order to remove them we would encode the twitter data to ascii and then decode this 
            ascii data</li>
        <li>Use regex to remove unnecessary content that do not provide any value while extracting sentiment. This includes URL's, emails, new line characters, 
            distracting single quotes and usernames.
        </li>
        <li>Analyze hashtags to see if they are useful. Since we have a lot of hashtags we find the count of words in hashtags to sort through the large amounts of data. 
            We find that few words like wow, innovation, scary, crazy can be used for sentiments but the number is small (5%) so we'd rather 
            eliminate all hashtags for easier processing since over 95% of the hashtags do not provide any valuable insight
        </li>
    </ul>
    </p>
  <p><b>Basic analysis</b><br>Use a barplot to depict sentiment scores to understand the distribution better. From the graph below, 
    we see maximum concentration of data in the sentiment 3 section. This might result in us being able to predict data with sentiment 3 more accurately  
    <img src="Photos/nlp_photos/sent_graph.png" alt="Nature" class="responsive">
Outlier detection can be performed using a boxplot. On creating a boxplot using the sentiment confidence column, we note that while there are no apparent outliers, the scores 
are skewed towards the higher end which means that the confidence in the sentiment score column is pretty high which is a positive thing. Thus the 
sentiment score would be a good variable to predict future sentiments
<img src="Photos/nlp_photos/boxplot.png" alt="Nature" class="responsive"></p>
  <p><i><b>Packages Used:-</b> Pandas, NumPy, Matplotlib</p></i></div>
  
  <div class="w3-padding w3-light-grey w3-display-container">
  <span onclick="this.parentElement.style.display='none'" class="w3-button w3-display-topright"></span>
  <h2>Tokenization & Lemmatization</h2>
  <p>Tokenization is the process of breaking down text into smaller chunks of data for easier processing. We also need to perform lemmatization in order to reduce 
    every word to its base root word. Perform tokenization using the tokenize function of nltk and create a custom Parts of Speech tagger in order to tag values as adjective, verb, noun and adverb 
    and use these tagged values for lemmatization. 
  </p>
  <p>In order to perform lemmatization, we use the lemmatizer function in nltk to lemmatize the tokenized dataset. Remove stop words and frequently occurring words that do 
    not add any value to sentiment. Create a list with all lemmatized words. Make 2 arrays one for lemmatized words and other for parts of speech tagging. 
    Create dataframe of lemma and parts of speech. Since we do not have a POS tagging for punctuation we add one called PU
    <img src="Photos/nlp_photos/pos1.png" alt="Nature" class="responsive">
    To find overall commonly occuring words we apply a filter of greater than 1000 occurences. We then find the most commonly occuring nouns, adjectives and punctuations in 
the dataset
<img src="Photos/nlp_photos/pos2.png" alt="Nature" class="responsive">
<img src="Photos/nlp_photos/pos3.png" alt="Nature" class="responsive">
<img src="Photos/nlp_photos/pos4.png" alt="Nature" class="responsive"></p>
  
  <p><i><b>Packages Used:-</b> nltk and other packages mentioned above</p></i></div>
  


<button onclick="myAccFunc('Demo1')" class="w3-padding-16 w3-theme w3-button w3-block w3-left-align" width=80%>Identifying areas which do not receive ration</button>

<div id="Demo1" class="w3-hide">
  <div class="w3-container">
  <h2>Background</h2>
  <p> There are three types of ration cards in India namely white, yellow and orange:-</p>
  <p><ul style="list-style-type:circle;">
  <li><b>Yellow Ration Cards: </b>Yellow colour ration cards are issued only to families who fall under the Below Poverty Line (BPL) category.</li>
  <li><b>Orange Ration Cards: </b>Families with a yearly income of more than Rs. 15,000 and less than 1 lakh can apply for the saffron/orange smart ration card.</li>
  <li><b>White Ration Cards: </b>Families with an annual income of Rs. 1 Lakh or above can apply for white smart ration cards.</li>
</ul>  </p>
<hr>
<h2>Analysis done</h2>
<p>As shown below The first step was trying to understand the overall dstribution of household by ther their ration colour.<br>
<font size="2"><i><b>Findings: </b>Here we found that most of the household have yellow or orange ration cards</p></i></font>
<p>The next step was trying to understand if all of the households within these 2 categories receive ration since they fall in the low income category<br>
<font size="2"><i><b>Findings: </b>While most do receive their ration which is positive we would like to understand which states/districts donot receive their ration</p></i></font>
<img src="Photos/ration_dist_flow.png" alt="Nature" class="responsive">
<p> We see from the charts below that Maharashtra is the state with the highest number of households and within this Pune is the city where the problem is prevalant<p>
<img src="Photos/state_dist_flow.png" alt="Nature" class="responsive">
<h2> <i>Thus the first focus of the NGO can be coordinating with the villages in Pune to ensure rationing to all their residents</h2></i>

  </div>
  </div>
<button onclick="myAccFunc('Demo2')" class="w3-padding-16 w3-theme w3-button w3-block w3-left-align" width=80%>Identify regions that spend the most on healthcare</button>
<div id="Demo2" class="w3-hide">
  <div class="w3-container">
  
<hr>
<h2>Analysis done</h2>
<p>We used a boxplot to determine the state spending maximum amount on healthcare<br>
<font size="2"><i><b>Findings: </b>Maharashtra has a large number of outliers that spend more than 2,500 rupees per month on healthcare</i></font></p><br>
<img src="Photos/box_plot_state.png" alt="Nature" class="responsive" style="max-height:300px; max-width:600px">
<p>We further drilled down and filtered for households spending greater than or equall to 2,500 rupees in Maharashtra<br>

<font size="2"><i><b>Findings: </b>Here we noticed that while Pune had a few outliers that spend a lot on healthcare, on an overall level Aurangabad has a higher average spent</p></i></font>

<img src="Photos/box_plot_district.png" alt="Nature" class="responsive" style="max-height:400px; max-width:800px">
<p>
<h2> <i>Thus the NGO can focus on these villages in Aurangabad who spend a large amount on healthcare and in turn should offer some subsidies for the same</h2></i>

  </div>
  </div>
<button onclick="myAccFunc('Demo3')" class="w3-padding-16 w3-theme w3-button w3-block w3-left-align">Identify regions that lack the presence of washrooms <br>within their house</button>
<div id="Demo3" class="w3-hide">
  <div class="w3-container">
<h2>Analysis</h2>
<p>We first try to identify the types of houses<br>
<font size="2"><i><b>Findings: </b>The most durable kind of house involves a complete cement slab. However the least percentage of houses seem to fall in this category
</p></i></font>
<p>The next step was trying to understand if most of the houses with no washrooms fall under the mud and metal sheet houses which is the weakest kind of house<br>
<font size="2"><i><b>Findings: </b>As expected those with houses made out of mud or metal sheets have almost a 50-50 distribution between those with their own toilets and those who do not. Comparing this ratio also lets us know that in case of houses completely made of cement which is the strongest also tend to have their own washrooms.
Thus we can focus on those who do not have washrooms in the metal sheet and mud and metal category
</p></i></font>
<img src="Photos/house_type_toilet.png" alt="Nature" class="responsive">
<p> We see from the charts below that maharashtra is the state with the highest number of households without a toilet and within this Pune is the city where the problem is prevalant<p>
<img src="Photos/state_dist_house.png" alt="Nature" class="responsive">
<h2> <i>Thus the first focus of the NGO can be coordinating with the villages in Pune to ensure construction of proper washrooms thus ensuring better hygiene</h2></i>

  </div>
  </div>
  <div class="w3-padding w3-white w3-display-container">
  <span onclick="this.parentElement.style.display='none'" class="w3-button w3-display-topright"></span>
  <h2>Dashboard Creation</h2><hr>
  <p>Once done with basic exploratory data analysis, the next step was creating a dashboard on Tableau to summarize different factors such as housing, rent, income etc</p>
  <p>The drop down above the map of india enables us to filter on both state and district to find all metrics in a particular location. Click <a href='https://public.tableau.com/app/profile/suparna.shetty/viz/NGO_Insights/Dashboard1'>here</a> to view the dashboard</p>
  
<footer class="w3-container w3-blue-grey">
  <h5></h5>
  <p class="w3-opacity"></p>
</footer>


</div>

</div>

<br>

<!-- Footer -->
<footer class="w3-container w3-theme-dark w3-padding-16">
  <h3></h3>
  <div style="position:relative;bottom:55px;" class="w3-tooltip w3-right">
    <span class="w3-text w3-theme-light w3-padding">Go To Top</span>    
    <a class="w3-text-white" href="#myHeader"><span class="w3-xlarge">
    <i class="fa fa-chevron-circle-up"></i></span></a>
  </div>
</footer>

<!-- Script for Sidebar, Tabs, Accordions, Progress bars and slideshows -->
<script>
// Side navigation
function w3_open() {
  var x = document.getElementById("mySidebar");
  x.style.width = "100%";
  x.style.fontSize = "40px";
  x.style.paddingTop = "10%";
  x.style.display = "block";
}
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
}

// Tabs
function openCity(evt, cityName) {
  var i;
  var x = document.getElementsByClassName("city");
  for (i = 0; i < x.length; i++) {
    x[i].style.display = "none";
  }
  var activebtn = document.getElementsByClassName("testbtn");
  for (i = 0; i < x.length; i++) {
    activebtn[i].className = activebtn[i].className.replace(" w3-dark-grey", "");
  }
  document.getElementById(cityName).style.display = "block";
  evt.currentTarget.className += " w3-dark-grey";
}

var mybtn = document.getElementsByClassName("testbtn")[0];
mybtn.click();

// Accordions
function myAccFunc(id) {
  var x = document.getElementById(id);
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else { 
    x.className = x.className.replace(" w3-show", "");
  }
}

// Slideshows
var slideIndex = 1;

function plusDivs(n) {
  slideIndex = slideIndex + n;
  showDivs(slideIndex);
}

function showDivs(n) {
  var x = document.getElementsByClassName("mySlides");
  if (n > x.length) {slideIndex = 1}    
  if (n < 1) {slideIndex = x.length} ;
  for (i = 0; i < x.length; i++) {
    x[i].style.display = "none";  
  }
  x[slideIndex-1].style.display = "block";  
}

showDivs(1);

// Progress Bars
function move() {
  var elem = document.getElementById("myBar");   
  var width = 5;
  var id = setInterval(frame, 10);
  function frame() {
    if (width == 100) {
      clearInterval(id);
    } else {
      width++; 
      elem.style.width = width + '%'; 
      elem.innerHTML = width * 1  + '%';
    }
  }
}
</script>

</body>
</html>
